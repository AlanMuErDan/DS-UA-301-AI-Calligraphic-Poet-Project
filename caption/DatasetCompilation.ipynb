{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a464a8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-23T07:17:54.048144Z",
     "iopub.status.busy": "2024-11-23T07:17:54.047582Z",
     "iopub.status.idle": "2024-11-23T07:17:55.405200Z",
     "shell.execute_reply": "2024-11-23T07:17:55.403954Z"
    },
    "papermill": {
     "duration": 1.367524,
     "end_time": "2024-11-23T07:17:55.408136",
     "exception": false,
     "start_time": "2024-11-23T07:17:54.040612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "# Input data files are available in the read-only \"/kaggle/input/\" directory\n",
    "# Output files are in the \"/kaggle/working/\" directory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb0aa8",
   "metadata": {
    "papermill": {
     "duration": 0.003646,
     "end_time": "2024-11-23T07:17:55.416090",
     "exception": false,
     "start_time": "2024-11-23T07:17:55.412444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This Jupyter Notebook is created as a Kaggle Notebook. This is because I will be compiling multiple datasets from Kaggle and it is easier to connect all the datasets using Kaggle Notebook (without downloading them). \n",
    "\n",
    "This will be used for the image captioning part of the project. We aim to use images that fit within the context of general themes present in SongCi. Each dataset has a different number of images so I aimed to have around the same number of images for each category and for each subcategory so there is no dataset imbalance. \n",
    "\n",
    "Here is a breakdown of the general categories for the images (the number after each category is the number of images for that category):\n",
    "\n",
    "* flowers /leaves\n",
    "    * Chrysanthemum (300)\n",
    "    * Peony (300)\n",
    "    * Orchid (300)\n",
    "    * Leaves (300)\n",
    "* weather\n",
    "    * Sunrise (300)\n",
    "    * Cloudy (300)\n",
    "    * Shine (253)\n",
    "    * Rime/Snow (300)\n",
    "* landscape\n",
    "    * Forest (300)\n",
    "    * Mountain (300)\n",
    "    * River/Lake/Sea (92 lake, 98 river, and 110 sea = 300 in total)\n",
    "    * Waterfall (300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45dcd4",
   "metadata": {
    "papermill": {
     "duration": 0.003536,
     "end_time": "2024-11-23T07:17:55.423116",
     "exception": false,
     "start_time": "2024-11-23T07:17:55.419580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "The names of the datasets that I am using and links:\n",
    "1. boat-vs-sea-images-dataset: https://www.kaggle.com/datasets/waqasahmedbasharat/boat-vs-sea-images-dataset?select=sea\n",
    "    * taking 100 images from the sea folder\n",
    "2. flower299: https://www.kaggle.com/datasets/bogdancretu/flower299\n",
    "    * taking 300 images from each of the Chrysanthemum, Peony, and Orchid folders\n",
    "3. river-vs-lake: https://www.kaggle.com/datasets/hariharanalm/river-vs-lake\n",
    "    * taking all the images: 190 images total\n",
    "4. visual-china: https://www.kaggle.com/datasets/protectoryao/visual-china\n",
    "    * taking 300 images of the waterfall folder\n",
    "5. landscape-recognition-image-dataset-12k-images: https://www.kaggle.com/datasets/utkarshsaxenadn/landscape-recognition-image-dataset-12k-images\n",
    "   * taking 300 images from the forest folder and 300 from the mountain folder\n",
    "6. multiclass-weather-dataset: https://www.kaggle.com/datasets/pratik2901/multiclass-weather-dataset/data\n",
    "    * take images from cloudy (300 images), sunrise (300 images), and shine folders (all 253 images)\n",
    "7. weather-dataset: https://www.kaggle.com/datasets/jehanbhathena/weather-dataset \n",
    "    * take 300 images from the rime folder\n",
    "8. leaf-detection: https://www.kaggle.com/datasets/alexo98/leaf-detection?select=train\n",
    "    * take 300 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981feea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T07:17:56.733026Z",
     "iopub.status.busy": "2024-11-23T07:17:56.730872Z",
     "iopub.status.idle": "2024-11-23T07:17:56.743499Z",
     "shell.execute_reply": "2024-11-23T07:17:56.741452Z"
    },
    "papermill": {
     "duration": 0.027594,
     "end_time": "2024-11-23T07:17:56.748887",
     "exception": false,
     "start_time": "2024-11-23T07:17:56.721293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil \n",
    "# copy images to output folders\n",
    "# want to have 50 test, 50 valid, and rest 200 in train for each category \n",
    "output_train = \"/kaggle/working/output_train/\"\n",
    "output_valid = \"/kaggle/working/output_valid/\"\n",
    "output_test = \"/kaggle/working/output_test/\"\n",
    "\n",
    "os.mkdir(output_train)\n",
    "os.mkdir(output_valid)\n",
    "os.mkdir(output_test)\n",
    "\n",
    "output_train_count = 0\n",
    "output_valid_count = 0\n",
    "output_test_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3624793b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T07:17:56.761422Z",
     "iopub.status.busy": "2024-11-23T07:17:56.760611Z",
     "iopub.status.idle": "2024-11-23T07:17:56.775518Z",
     "shell.execute_reply": "2024-11-23T07:17:56.773895Z"
    },
    "papermill": {
     "duration": 0.028081,
     "end_time": "2024-11-23T07:17:56.781644",
     "exception": false,
     "start_time": "2024-11-23T07:17:56.753563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to copy images\n",
    "def copy_image (input_dir, output_train_count, output_valid_count, output_test_count, train =200, valid = 50, test = 50):\n",
    "    total = train + valid + test\n",
    "    valid_test = valid + test\n",
    "\n",
    "    files = []\n",
    "    for _,_,temp in os.walk(input_dir):\n",
    "        files = temp\n",
    "    \n",
    "    # image extension\n",
    "    extension = files[0].split(\".\")[-1]\n",
    "    \n",
    "    # also make sure that the output images are ordered numerically \n",
    "    for i in files[:test]:\n",
    "        shutil.copy(os.path.join(input_dir,i), os.path.join(output_test,str(output_test_count).zfill(4) + \".\" + extension))\n",
    "        output_test_count+=1\n",
    "    for i in files[test:valid_test]:\n",
    "        shutil.copy(os.path.join(input_dir,i), os.path.join(output_valid,str(output_valid_count).zfill(4) + \".\" + extension))\n",
    "        output_valid_count+=1\n",
    "    if len(files) <total:\n",
    "        for i in files[valid_test:]:\n",
    "            shutil.copy(os.path.join(input_dir,i), os.path.join(output_train,str(output_train_count).zfill(4) + \".\" + extension))\n",
    "            output_train_count+=1\n",
    "    else:\n",
    "        for i in files[valid_test:total]:\n",
    "            shutil.copy(os.path.join(input_dir,i), os.path.join(output_train,str(output_train_count).zfill(4) + \".\" + extension))\n",
    "            output_train_count+=1\n",
    "\n",
    "    # return it so it can be updated globally \n",
    "    return output_train_count, output_valid_count, output_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9dbd398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T07:17:56.794516Z",
     "iopub.status.busy": "2024-11-23T07:17:56.793134Z",
     "iopub.status.idle": "2024-11-23T07:17:56.803564Z",
     "shell.execute_reply": "2024-11-23T07:17:56.802047Z"
    },
    "papermill": {
     "duration": 0.019603,
     "end_time": "2024-11-23T07:17:56.806002",
     "exception": false,
     "start_time": "2024-11-23T07:17:56.786399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dirs = []\n",
    "dirname = \"/kaggle/input\"\n",
    "\n",
    "\n",
    "# adding all the flower/leaves images first\n",
    "# taking 300 images from each of the Chrysanthemum, Peony, and Orchid folders from flower299\n",
    "input_dirs.append(os.path.join(dirname, 'flower299/Flowers299', \"Chrysanthemum\"))\n",
    "input_dirs.append(os.path.join(dirname, 'flower299/Flowers299', \"Peony\"))\n",
    "input_dirs.append(os.path.join(dirname, 'flower299/Flowers299', \"Orchid\"))\n",
    "# add leaf images (take 300 from dataset)\n",
    "input_dirs.append(os.path.join(dirname, 'leaf-detection', \"train\"))\n",
    "\n",
    "\n",
    "\n",
    "# add weather images\n",
    "# take 300 images from sunrise and cloudy and take all the images in shine (253)\n",
    "input_dirs.append(os.path.join(dirname, 'multiclass-weather-dataset/Multi-class Weather Dataset', \"Cloudy\"))\n",
    "input_dirs.append(os.path.join(dirname, 'multiclass-weather-dataset/Multi-class Weather Dataset', \"Shine\"))\n",
    "input_dirs.append(os.path.join(dirname, 'multiclass-weather-dataset/Multi-class Weather Dataset', \"Sunrise\"))\n",
    "# take 300 images from rime\n",
    "# taking images from rime because context of the images are more related to SongCi themes than snow\n",
    "input_dirs.append(os.path.join(dirname, \"weather-dataset/dataset\", \"rime\"))\n",
    "\n",
    "\n",
    "\n",
    "# add landscape images\n",
    "# taking 300 images from the forest folder and 300 from the mountain folder\n",
    "input_dirs.append(os.path.join(dirname, \"landscape-recognition-image-dataset-12k-images/Landscape Classification/Landscape Classification/Training Data\", \"Forest\"))\n",
    "input_dirs.append(os.path.join(dirname, \"landscape-recognition-image-dataset-12k-images/Landscape Classification/Landscape Classification/Training Data\", \"Mountain\"))\n",
    "# taking 300 images from waterfall \n",
    "# Huangguoshu is the name of the waterfall \n",
    "# even though it is the same waterfall, the images are from different angles/lighting so it is still diverse\n",
    "input_dirs.append(os.path.join(dirname, \"visual-china/Visual_China/train/Huangguoshu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04253400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T07:17:56.815247Z",
     "iopub.status.busy": "2024-11-23T07:17:56.814622Z",
     "iopub.status.idle": "2024-11-23T07:18:26.389308Z",
     "shell.execute_reply": "2024-11-23T07:18:26.388051Z"
    },
    "papermill": {
     "duration": 29.582366,
     "end_time": "2024-11-23T07:18:26.391814",
     "exception": false,
     "start_time": "2024-11-23T07:17:56.809448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dir in input_dirs:\n",
    "    output_train_count, output_valid_count, output_test_count = copy_image(dir,output_train_count, output_valid_count, output_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50f1ba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T07:18:26.400499Z",
     "iopub.status.busy": "2024-11-23T07:18:26.400072Z",
     "iopub.status.idle": "2024-11-23T07:18:31.793532Z",
     "shell.execute_reply": "2024-11-23T07:18:31.792124Z"
    },
    "papermill": {
     "duration": 5.401244,
     "end_time": "2024-11-23T07:18:31.796500",
     "exception": false,
     "start_time": "2024-11-23T07:18:26.395256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# special case for River/Lake/Sea and Waterfall lanscape images\n",
    "\n",
    "# River/Lake/Sea (92 lake, 98 river, and 110 sea = 300 in total)\n",
    "# want approximately even representation of each in train/test/valid\n",
    "# test/valid: 15 lake, 16 river, 19 sea\n",
    "# train: 62 lake, 66 river, 72 sea\n",
    "temp = os.path.join(dirname,\"river-vs-lake/River vs Lake\", \"lake water\")\n",
    "output_train_count, output_valid_count, output_test_count = copy_image(temp,output_train_count, output_valid_count, output_test_count,train = 62, valid = 15, test = 15)\n",
    "\n",
    "temp = os.path.join(dirname,\"river-vs-lake/River vs Lake\", \"river water\")\n",
    "output_train_count, output_valid_count, output_test_count = copy_image(temp,output_train_count, output_valid_count, output_test_count,train = 66, valid = 16, test = 16)\n",
    "\n",
    "temp = os.path.join(dirname,\"boat-vs-sea-images-dataset\", \"sea\")\n",
    "output_train_count, output_valid_count, output_test_count = copy_image(temp,output_train_count, output_valid_count, output_test_count,train = 72, valid = 19, test = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9227914a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T07:18:31.806385Z",
     "iopub.status.busy": "2024-11-23T07:18:31.805161Z",
     "iopub.status.idle": "2024-11-23T07:18:31.816968Z",
     "shell.execute_reply": "2024-11-23T07:18:31.814922Z"
    },
    "papermill": {
     "duration": 0.019361,
     "end_time": "2024-11-23T07:18:31.819660",
     "exception": false,
     "start_time": "2024-11-23T07:18:31.800299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2353\n",
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "# return the number of images\n",
    "# should have 2353 images for the training set and 600 images for the validation and test sets \n",
    "for _,_,files in os.walk(output_train):\n",
    "    print(len(files))\n",
    "for _,_,files in os.walk(output_test):\n",
    "    print(len(files))\n",
    "for _,_,files in os.walk(output_valid):\n",
    "    print(len(files))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 707640,
     "sourceId": 1270808,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 799266,
     "sourceId": 1371618,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1361382,
     "sourceId": 2261878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1715246,
     "sourceId": 2854929,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2707450,
     "sourceId": 4669588,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3817861,
     "sourceId": 6615649,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3978147,
     "sourceId": 7018545,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4329451,
     "sourceId": 7438735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.561773,
   "end_time": "2024-11-23T07:18:32.446539",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-23T07:17:49.884766",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
